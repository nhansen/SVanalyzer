#!/usr/bin/env perl
# $Id:$

use strict;
use warnings;
use Getopt::Long;
use Pod::Usage;
use Log::Log4perl qw(:easy);
use GTB::File qw(Open);
use NHGRI::SVanalyzer::Comp;

our %Opt;

=head1 NAME

SVmerge - group structural variants from one or more VCF files by calculating a distance matrix between nearby variants, then finding connected components of a graph.

=head1 SYNOPSIS

  SVmerge --ref <reference FASTA file> --variants <VCF-formatted variant file>
  SVmerge --ref <reference FASTA file> --fof <file of paths to VCF-formatted variant file>
  SVmerge --ref <reference FASTA file> --distance_file <distance file produced by previous run> --variants <VCF-formatted variant file>

=head1 DESCRIPTION

The program steps through the specified VCF files, calculating distances to other variants in the files that are nearby by comparing alternate haplotypes. It then reports clusters of variants, and prints a VCF file of unique variants. Alternatively, a file of previously-calculated distances can be provided with the --distance_file option, and the clustering can be skipped with the option --skip_clusters.

=cut

#------------
# Begin MAIN 
#------------

$|=1;

my $edlib = `which edlib-aligner`;
if (!$edlib) {
    die "Running SVmerge requires that the edlib-aligner (http://martinsosic.com/edlib/) executable be in your Linux path.\n";
}
else {
    chomp $edlib;
}

my $commandline = join " ", @ARGV;
$commandline = $0." $commandline";

process_commandline();

my $ref_fasta = $Opt{ref};
my $vcf_file = $Opt{variants};
my $fof_file = $Opt{fof};
my $prefix = $Opt{prefix};
my $vcf_output = $prefix.".clustered.vcf";
my $dist_output = $prefix.".distances";
my $dist_input = $Opt{distance_file};
my $min_size = $Opt{'minsize'};

# Threshold options:
my $max_distance = $Opt{maxdist};
my $max_relshift = $Opt{relshift};
my $max_relsizediff = $Opt{relsizediff};
my $max_reldist = $Opt{reldist};

# set up logging:
$Opt{'loglevel'} = ($Opt{debug}) ? $DEBUG : 
                   (($Opt{verbose}) ? $INFO : $WARN);

Log::Log4perl->easy_init( { level => $Opt{'loglevel'},
                            file => "$prefix.log" } );

WARN($commandline);

my ($rh_distances, $ra_nodes, $rh_nodes, $ra_node_edges); # distances between connected nodes
if ($dist_input) { # distances were calculated previously
    WARN("Reading distances from file $dist_input");
   ($rh_distances, $ra_nodes, $rh_nodes, $ra_node_edges) = read_distances($dist_input);
}
else {
    if ($vcf_file) {
        WARN("Calculating distances between neighboring variants in $vcf_file");
    }
    elsif ($fof_file) {
        WARN("Calculating distances between neighboring variants in VCF files listed in $fof_file");
    }
   ($rh_distances, $ra_nodes, $rh_nodes, $ra_node_edges) = calc_distances($vcf_file, $fof_file);
}

if (!$Opt{skip_clusters}) {
    WARN("Writing vcf file $vcf_output of clustered variants");
    my ($rh_cluster_info, $rh_all_clustered_variants) = find_clusters($rh_distances, $ra_nodes, $rh_nodes, $ra_node_edges);
    write_cluster_vcf($vcf_file, $fof_file, $vcf_output, $rh_cluster_info, $rh_all_clustered_variants, $rh_nodes);
}

WARN("Done");

#------------
# End MAIN
#------------

sub process_commandline {
    # Set defaults here
    %Opt = ( maxdist => 2000, prefix => 'merged', relshift => 0.2, relsizediff => 0.2, reldist => 0.2, minsize => 0, delimiter => ':' );
    GetOptions(\%Opt, qw( ref=s variants=s fof=s distance_file=s maxdist=i relshift=f relsizediff=f reldist=f minsize=i skip_clusters seqspecific nocleanup prefix=s delimiter=s manual help+ version verbose debug)) || pod2usage(0);
    if ($Opt{manual})  { pod2usage(verbose => 2); }
    if ($Opt{help})    { pod2usage(verbose => $Opt{help}-1); }
    if ($Opt{version}) { die "SVmerge, ", q$Revision:$, "\n"; }

    if (!$Opt{ref} || (!$Opt{variants} && !$Opt{fof})) {
        pod2usage();
    }

    if ($Opt{variants} && (!(-r $Opt{variants}))) {
        die "Variants file $Opt{variants} does not exist or is not readable!\n";
    }
}

sub open_files_and_sort {
    my $vcf_file = shift;
    my $vcf_fof = shift;

    my @vcf_files = (($vcf_file) && (-r $vcf_file)) ? ($vcf_file) : ();
    if ($vcf_fof) {
        my $fof_fh = Open("$vcf_fof");
        while (<$fof_fh>) {
            next if (/^#/); # skip comment lines
            if (/^(\S+)/) {
                my $this_file = $1;
                if (-r $this_file) {
                    push @vcf_files, $this_file;
                }
            }
        }
        close $fof_fh;
    }

    if (!@vcf_files) {
        die "No valid VCF files specified in input!\n";
    }

    my @commands = ();
    foreach my $vcf_file (@vcf_files) {
        my $this_command = ($vcf_file =~ /gz$/) ? "gunzip -c $vcf_file" : "cat $vcf_file";
        push @commands, $this_command;
    }
    my $header_capture = ($vcf_files[0] =~ /gz$/) ? "gunzip -c $vcf_files[0] | grep \'#\'" : "grep \'#\' $vcf_files[0]";
    my $commandpipe = join ';', @commands;
    $commandpipe = "(" . $header_capture . "; (" . $commandpipe . ") | grep -v '#' | sort -k1,1 -k2,2n ) |";
    my $variant_fh = Open($commandpipe);

    return $variant_fh;
}

sub read_distances {
    my $distance_file = shift;
    my $dist_fh = Open($distance_file);

    my @nodes = ();
    my @node_edges = (); # array of node connections
    my %node_index = (); # indices of nodes
    my %distances = (); # hash of distance arrays for pairs of ids
    
    while (<$dist_fh>) {
        chomp;
        s/^DIST\s//; # some versions of distance file have "DIST\t" at beginning of each line
        my $line = $_;
        my @fields = split /\t/, $line; # first two fields must be ids, last four dist measures
        my $id1 = $fields[0];
        my $id2 = $fields[1];
        my $posdiff = $fields[$#fields-3];
        my $relshift = $fields[$#fields-2];
        my $relsizediff = $fields[$#fields-1];
        my $reldist = $fields[$#fields];
        next if ($id1 eq 'ID1');
        next if ($id1 =~ /Read \d+ SVs/);
        #next if (!$id1);
    
        if (!(defined($posdiff)) || ($posdiff !~ /(\d+)/)) {
            warn "Skipping line--not enough fields: $line";
            next;
        }

        if ($posdiff <= $max_distance && $relshift <= $max_relshift &&
            $relsizediff <= $max_relsizediff && $reldist <= $max_reldist) {
            my $index1 = $node_index{$id1};
            if (!(defined($index1))) {
                push @nodes, $id1;
                $index1 = $#nodes + 1;
                $node_index{$id1} = $index1;
            }
            my $index2 = $node_index{$id2};
            if (!(defined($index2))) {
                push @nodes, $id2;
                $index2 = $#nodes + 1;
                $node_index{$id2} = $index2;
            }
            push @{$node_edges[$index1 - 1]}, $index2 - 1;
            push @{$node_edges[$index2 - 1]}, $index1 - 1;
        }
        my $idlesser = (($id1 cmp $id2) > 0) ? $id2 : $id1;
        my $idgreater = (($id1 cmp $id2) > 0) ? $id1 : $id2;
        $distances{"$idlesser:$idgreater"} = [$posdiff, $relshift, $relsizediff, $reldist];
    }

    close $dist_fh;

    return ({%distances}, [@nodes], {%node_index}, [@node_edges]);
}

sub calc_distances {

    my $vcf_file = shift;
    my $fof_file = shift;

    my $rh_current_last_sv; # to check for sorting
    my $total_svs = 0;
    my @current_neighborhood_svs = ();

    my @nodes = ();
    my @node_edges = ();
    
    my $dist_fh = Open($dist_output, "w");
    print $dist_fh "DIST\tID1\tID2\tAVGALTLENGTH\tALTLENGTHDIFF\tAVGSIZE\tSIZEDIFF\tEDITDIST\tMAXSHIFT\tPOSDIFF\tRELSHIFT\tRELSIZEDIFF\tRELDIST\n";
    
    my $sortedvcf_fh = open_files_and_sort($vcf_file, $fof_file);
    my %distances = (); # hash of distance arrays for pairs of ids
    my %node_index = (); # indices of nodes
    my %unique_ids = (); # to check for uniqueness of IDs across files

    while (my $rh_sv = retrieve_next_sorted_sv($sortedvcf_fh)) {
    
        next if (!($rh_sv->{chrom}));
    
        my $id2 = $rh_sv->{id};
        if ($unique_ids{$id2}) {
            die "Structural variant id $id2 seen more than once in merged set--please specify a unique id for each variant\n";
        }
        else {
            $unique_ids{$id2} = 1;
        }
        my $index2 = $node_index{$id2};
        if (!(defined($index2))) {
            push @nodes, $id2;
            $index2 = $#nodes + 1;
            $node_index{$id2} = $index2;
        }

        # check sorted:
        check_sort($rh_current_last_sv, $rh_sv);
        $rh_current_last_sv = $rh_sv;
    
        $total_svs++;
    
        if (!@current_neighborhood_svs) {
            push @current_neighborhood_svs, $rh_sv;
            next;
        }
        else { # compare current SV to all SV's in the neighborhood
    
            # remove different chromosome or distant SVs:
            while (@current_neighborhood_svs && ($current_neighborhood_svs[0]->{chrom} ne $rh_sv->{chrom} || $current_neighborhood_svs[0]->{pos} < $rh_sv->{pos} - $max_distance)) {
                shift @current_neighborhood_svs;
            }
    
            # if chance of match, compare alternate alleles with edlib:
            for (my $i=0; $i<=$#current_neighborhood_svs; $i++) {
                my $rh_neighborhood_sv = $current_neighborhood_svs[$i];
                my $comp_obj = NHGRI::SVanalyzer::Comp->new(-ref_fasta => $ref_fasta, 
                                                            -sv1_info => $rh_neighborhood_sv,
                                                            -sv2_info => $rh_sv);

                # assign nodes if needed:
                my $id1 = $rh_neighborhood_sv->{id};
 
                my $index1 = $node_index{$id1};
                if (!(defined($index1))) {
                    push @nodes, $id1;
                    $index1 = $#nodes + 1;
                    $node_index{$id1} = $index1;
                }
 
                if (($rh_neighborhood_sv->{chrom} eq $rh_sv->{chrom}) && (abs($rh_neighborhood_sv->{pos} - $rh_sv->{pos}) <= $max_distance) &&
                     $comp_obj->potential_match( -relsizediff => $max_relsizediff, -relshift => $max_relshift)) {
                    my $rh_distance_metrics = $comp_obj->calc_distance();
                    next if (!(defined($rh_distance_metrics->{'edit_distance'})));
                    my $edit_dist = $rh_distance_metrics->{'edit_distance'};
                    my $max_shift = $rh_distance_metrics->{'max_shift'};
                    my $altlength_diff = $rh_distance_metrics->{'altlength_diff'};
                    my $altlength_avg = $rh_distance_metrics->{'altlength_avg'};
                    my $size_diff = $rh_distance_metrics->{'size_diff'};
                    my $size_avg = $rh_distance_metrics->{'size_avg'};
                    my $shared_denominator = $rh_distance_metrics->{'shared_denominator'};
    
                    my $pos_diff = abs($rh_neighborhood_sv->{pos} - $rh_sv->{pos});
                    # divide maximum shift by the minimum absolute size of the two variants:
                    my $d1 = abs($max_shift)/$shared_denominator;
                    # divide the size difference of the two indels by the average absolute size of the difference
                    my $d2 = abs($size_diff)/$shared_denominator;
                    # divide edit distance by the minimum alternate haplotype length:
                    my $d3 = abs($edit_dist)/$shared_denominator;
                    print $dist_fh "DIST\t$id1\t$id2\t$altlength_avg\t$altlength_diff\t$size_avg\t$size_diff\t$edit_dist\t$max_shift\t$pos_diff\t$d1\t$d2\t$d3\n";
                    if ($pos_diff <= $max_distance && $d1 <= $max_relshift &&
                        $d2 <= $max_relsizediff && $d3 <= $max_reldist) {
                        push @{$node_edges[$index1 - 1]}, $index2 - 1;
                        push @{$node_edges[$index2 - 1]}, $index1 - 1;
                        my $idlesser = (($id1 cmp $id2) > 0) ? 
                                         $id2 : $id1;
                        my $idgreater = (($id1 cmp $id2) > 0) ? 
                                         $id1 : $id2;
                        $distances{"$idlesser:$idgreater"} = [$pos_diff, $d1, $d2, $d3];
                    }
                }
            }
    
            # add this SV to the current neighborhood:
            push @current_neighborhood_svs, $rh_sv;
        }
    }

    close $sortedvcf_fh;
    close $dist_fh;
    
    return ({%distances}, [@nodes], {%node_index}, [@node_edges]);
}

sub retrieve_next_sorted_sv {
    my $variant_fh = shift;

    my $next_line = <$variant_fh>;

    if (!$next_line) {
        return $next_line;
    }
    chomp $next_line;
    if ($next_line =~ /^(\S+)\t(\d+)\t(\S+)\t(\S+)\t(\S+)\t(\S+)\t(\S+)\t(\S+)/) {
        my ($chrom, $start, $id, $ref, $alt, $info) = ($1, $2, $3, $4, $5, $8);
        $ref = uc($ref);
        $alt = uc($alt);
 
        my $reflength = length($ref);
        my $altlength = length($alt);
 
        my $end; # if we have sequence, end will be determined as last base of REF, otherwise, from END=
        if (($ref =~ /^([ATGCN]+)$/) && ($alt =~ /^([ATGCN]+)$/)) {
            $end = $start + $reflength - 1;
        }
        elsif ($info =~ /SVTYPE=BND/ || $info =~ /SVTYPE=UNK/) {
            return {};
        }
        else { # check for END= INFO tag
            INFO("Skipping non-ATGC ref or alt:$next_line");
            return {};
        }

        if ($min_size) { # skip SVs that are too small and return empty hash
            my $svsize = ($reflength > $altlength) ? $reflength - $altlength : $altlength - $reflength;
            if ($svsize < $min_size) {
                INFO("Skipping variant $id--size smaller than specified minimum of $min_size");    
                return {};
            } 
        }

        return {'chrom' => $chrom, 'pos' => $start, 'start' => $start, 'end' => $end, 'id' => $id, 'ref' => $ref,
                'alt' => $alt, 'reflength' => $reflength, 'altlength' => $altlength};
    }
    elsif ($next_line =~ /^#/) { # comment
        return {'chrom' => undef};
    }
    else {
        die "Unexpected VCF line:\n$next_line";
    }
}

sub find_clusters {
    my $rh_distances = shift;
    my $ra_nodes = shift;
    my $rh_nodes = shift;
    my $ra_node_edges = shift;

    my @visited = ();
    my @nodes = @{$ra_nodes};
    for (my $i=0; $i<=$#nodes; $i++) {
        $visited[$i] = 0;
    }
    
    my %cluster_info = ();
    my %clustered_variants = ();
    for (my $i=0; $i<=$#nodes; $i++) {
        next if ($visited[$i]);
        my @connectednodes = dfs($i, $ra_node_edges, \@visited);
        my @nodenames = map { $nodes[$_] } @connectednodes;
        my $nodestring = join $Opt{delimiter}, @nodenames;
        my ($clustercall, $no_cluster_calls, $dummynodestring, $no_exact_matches, $exactsubcluster, $maxdist1, $maxdist2, $maxdist3) =
                     analyze_cluster($nodestring, $rh_distances);
        DEBUG("Chose $clustercall as cluster rep");
        $cluster_info{$clustercall} = {'nodestring' => $nodestring, 'exactstring' => $exactsubcluster, 'maxdists' => [$maxdist1, $maxdist2, $maxdist3]};
        foreach my $nodename (@nodenames) {
            $clustered_variants{$nodename} = 1;
        }
    }
   
    return ({%cluster_info}, {%clustered_variants}); 
}

sub write_cluster_vcf {
    my $vcf_file = shift;
    my $fof_file = shift;
    my $vcf_output = shift;
    my $rh_cluster_info = shift;
    my $rh_clustered_variants = shift;
    my $rh_node_index = shift;

    my $sortedvcf_fh = open_files_and_sort($vcf_file, $fof_file);
    my $newvcf_fh = Open($vcf_output, "w");

    my $ra_allowed_info_fields = [];
    while (<$sortedvcf_fh>) {
        if (/^##/) {
            print $newvcf_fh $_; # include original VCF header in new file

            if (/^##INFO=<ID=([^,]+)/) {
                push @{$ra_allowed_info_fields}, $1;
            }
        }
        elsif (/^#CHROM/) { # include new INFO lines
            my $chromline = $_;
            print_info_lines($newvcf_fh);
            print $newvcf_fh $chromline; # include original VCF header in new file
        }
        else {
            chomp;
            my @fields = split /\t/, $_;
            my $id_field = $fields[2];

            if ($rh_cluster_info->{$id_field}) { # this is a cluster rep!
                DEBUG("ID $id_field is a cluster rep--will print VCF record");
                write_vcf_line_with_info($newvcf_fh, \@fields, $rh_cluster_info->{$id_field}, $ra_allowed_info_fields);
            }
            elsif (!($rh_clustered_variants->{$id_field})) { # singleton--print unless --seqspecific option is specified and variant has been skipped for clustering
                DEBUG("ID $id_field is a singleton--will print VCF record unless it was not initially considered due to --seqspecific");
                if ((defined($rh_node_index->{$id_field})) || !$Opt{seqspecific}) {
                    write_vcf_line_with_info($newvcf_fh, \@fields, {'nodestring' => $id_field, 'exactstring' => $id_field, 'maxdists' => ['NA', 'NA', 'NA']}, $ra_allowed_info_fields); 
                    DEBUG("Wrote ID $id_field to VCF file");
                }
            }
            else {
                DEBUG("Ignoring ID $id_field--clustered but not a cluster rep");
            }
        }
    }
    close $sortedvcf_fh;
}

sub dfs {
    my $i = shift;
    my $ra_nodeedges = shift;
    my $ra_visited = shift;

    my @stack = ();
    push @stack, $i;

    my @connectednodes = ();
    while (@stack) {
        my $j = pop @stack;
        if (!$ra_visited->[$j]) {
            $ra_visited->[$j] = 1;
            push @connectednodes, $j;
            foreach my $k (@{$ra_nodeedges->[$j]}) {
                next if ($ra_visited->[$k]);
                push @stack, $k;
            }
        }
    }

    return @connectednodes;
}

sub analyze_cluster {
    my $nodestring = shift;
    my $rh_dists = shift;

    my @nodes = split /$Opt{delimiter}/, $nodestring;
    my $no_cluster_calls = @nodes;

    if ($no_cluster_calls == 1) {
        return ($nodestring, 1, $nodestring, 1, $nodestring, 0, 0, 0);
    }

    # at least two calls--analyze exact subclusters
    my ($maxdist1, $maxdist2, $maxdist3) = (0, 0, 0);
    my @exact_clusters = @nodes;
    my %node_cluster = map { $exact_clusters[$_] => $_ } ( 0 .. $#nodes ); # all start out in their own cluster
    for (my $i=0; $i<=$#nodes; $i++) {
        for (my $j=$i + 1; $j<=$#nodes; $j++) {
            my $idlesser = (($nodes[$i] cmp $nodes[$j]) > 0) ? $nodes[$j] : $nodes[$i];
            my $idgreater = (($nodes[$i] cmp $nodes[$j]) > 0) ? $nodes[$i] : $nodes[$j];
            if (!$rh_dists->{"$idlesser$Opt{delimiter}$idgreater"}) {
                next;
            }
            my ($thisposdist, $this_dist1, $this_dist2, $this_dist3) = @{$rh_dists->{"$idlesser$Opt{delimiter}$idgreater"}};
            $maxdist1 = ($this_dist1 > $maxdist1) ? $this_dist1 : $maxdist1;
            $maxdist2 = ($this_dist2 > $maxdist2) ? $this_dist2 : $maxdist2;
            $maxdist3 = ($this_dist3 > $maxdist3) ? $this_dist3 : $maxdist3;
            if (!$this_dist1 && !$this_dist2 && !$this_dist3) { # exact match--merge exact clusters
                if ($node_cluster{$idlesser} != $node_cluster{$idgreater}) { # different clusters merge greater into lesser
                    if (!($exact_clusters[$node_cluster{$idgreater}])) {
                        INFO("Empty node cluster for $idgreater being merged into $idlesser!");
                    }
                    my $old_cluster_index = $node_cluster{$idgreater};
                    my $new_cluster_index = $node_cluster{$idlesser};
                    $exact_clusters[$new_cluster_index] .= "$Opt{delimiter}".$exact_clusters[$old_cluster_index];
                    $exact_clusters[$old_cluster_index] = '';
                    foreach my $key (keys %node_cluster) {
                        if ($node_cluster{$key} == $old_cluster_index) {
                            $node_cluster{$key} = $new_cluster_index;
                        }
                    }
                }
                else {
                    DEBUG("$idgreater and $idlesser are already in the same exact cluster!");
                } 
            }

        }
    }

    my @unique_clusters = grep { $_ ne '' } @exact_clusters;
    my @largest_exact_clusters = ();
    my $max_exact_clustersize = 0;

    foreach my $unique_cluster (@unique_clusters) {
        my @unique_vars = split /$Opt{delimiter}/, $unique_cluster;
        my $no_vars = @unique_vars;
        if ($no_vars == $max_exact_clustersize) { # it's a tie
            push @largest_exact_clusters, $unique_cluster;
            $max_exact_clustersize = $no_vars;
        }
        elsif ($no_vars > $max_exact_clustersize) { # replace
            @largest_exact_clusters = ($unique_cluster);
            $max_exact_clustersize = $no_vars;
        }
    }

    my $exactsubcluster = $largest_exact_clusters[rand()*$#largest_exact_clusters];
    my @exact_vars = split /$Opt{delimiter}/, $exactsubcluster;
    my $clustercall = $exact_vars[rand()*$#exact_vars];

    return ($clustercall, $no_cluster_calls, $nodestring, $max_exact_clustersize, $exactsubcluster, $maxdist1, $maxdist2, $maxdist3);
}

sub write_vcf_line_with_info {
    my $vcf_fh = shift;
    my $ra_vcf_fields = shift;
    my $rh_cluster_info = shift;
    my $ra_allowed_info_fields = shift;

    my $clustersvcalls = $rh_cluster_info->{'nodestring'};
    my @clustercalls = split /$Opt{delimiter}/, $clustersvcalls;
    my $no_clustersvcalls = @clustercalls;
    my $exactsvcalls = $rh_cluster_info->{'exactstring'};
    my @exactcalls = split /$Opt{delimiter}/, $exactsvcalls;
    my $no_exactsvcalls = @exactcalls;
    my $ra_maxdists = $rh_cluster_info->{'maxdists'};

    my $info_field = $ra_vcf_fields->[7];
    my @info_entries = ($info_field eq '.') ? () : split /;/, $info_field;
    my @allowed_info_entries = ();
    foreach my $info_entry (@info_entries) {
        my $info_id = $info_entry;
        $info_id =~ s/=.*$//;
        if (grep {$_ eq $info_id} @{$ra_allowed_info_fields}) {
            push @allowed_info_entries, $info_entry;
        }
    }
    @info_entries = @allowed_info_entries;

    my ($maxshiftdist, $maxsizediff, $maxeditdist) = @{$ra_maxdists};

    push @info_entries, "ClusterIDs=$clustersvcalls";
    push @info_entries, "NumClusterSVs=$no_clustersvcalls";
    push @info_entries, "ExactMatchIDs=$exactsvcalls";
    push @info_entries, "NumExactMatchSVs=$no_exactsvcalls";
    push @info_entries, "ClusterMaxShiftDist=$maxshiftdist";
    push @info_entries, "ClusterMaxSizeDiff=$maxsizediff";
    push @info_entries, "ClusterMaxEditDist=$maxeditdist";

    $ra_vcf_fields->[7] = join ';', @info_entries;
    $ra_vcf_fields->[8] = '.'; # no format/genotype for now
    $ra_vcf_fields->[9] = '.'; # no format/genotype for now

    my $vcf_record = join "\t", @{$ra_vcf_fields};

    print $vcf_fh "$vcf_record\n";
}

sub print_info_lines {
    my $fh = shift;
    # print lots of INFO lines
    print $fh "##INFO=<ID=ClusterIDs,Number=1,Type=String,Description=\"IDs of SVs that cluster with this SV\">\n";
    print $fh "##INFO=<ID=NumClusterSVs,Number=1,Type=Integer,Description=\"Total number of SVs in this cluster\">\n";
    print $fh "##INFO=<ID=ExactMatchIDs,Number=1,Type=String,Description=\"IDs of SVs that are exactly the same call as this SV\">\n";
    print $fh "##INFO=<ID=NumExactMatchSVs,Number=1,Type=Integer,Description=\"Total number of SVs in this exact cluster\">\n";
    print $fh "##INFO=<ID=ClusterMaxShiftDist,Number=1,Type=Float,Description=\"Maximum relative shift distance between two SVs in this cluster\">\n";
    print $fh "##INFO=<ID=ClusterMaxSizeDiff,Number=1,Type=Float,Description=\"Maximum relative size difference between two SVs in this cluster\">\n";
    print $fh "##INFO=<ID=ClusterMaxEditDist,Number=1,Type=Float,Description=\"Maximum relative edit distance between two SVs in this cluster\">\n";
}

sub check_sort {
    my $rh_last_sv = shift;
    my $rh_this_sv = shift;

    if (($rh_last_sv->{chrom}) && ($rh_this_sv->{chrom}) && ($rh_last_sv->{chrom} eq $rh_this_sv->{chrom}) && ($rh_last_sv->{pos}) && ($rh_this_sv->{pos}) && ($rh_last_sv->{pos} > $rh_this_sv->{pos})) {
        die "VCF file is not sorted ($rh_last_sv->{chrom}, $rh_last_sv->{pos}, $rh_this_sv->{pos}\n";
    }
}

__END__

=head1 OPTIONS

=over 4

=item B<--help|--manual>

Display documentation.  One C<--help> gives a brief synopsis, C<-h -h> shows
all options, C<--manual> provides complete documentation.

=item B<--prefix>

Specify a prefix to be used to create output file names: files of distance metric values will be named "prefix.distances" and the output, clustered VCF file will be named "prefix.clustered.vcf".

=item B<--variants>

Specify the path to a VCF file of variants to merge. These variants will be considered in combination with any specified using the --fof option.

=item B<--fof>

Specify the path to a file of files with paths to VCF files of variants to merge. These variants will be considered in combination with any specified using the --variants option.

=item B<--maxdist>

Specify the maximum distance in bases between the positions of SVs that can be merged.

=item B<--variantdelimiter>

Specify the ASCII character to be used as a delimiter when forming clusters. This must be a character that is not contained in any of the cluster IDs in order for SVmerge to give reliable results.

=back

=head1 AUTHOR

 Nancy Hansen - nhansen@mail.nih.gov

=head1 LEGAL

This software/database is "United States Government Work" under the terms of
the United States Copyright Act.  It was written as part of the authors'
official duties for the United States Government and thus cannot be
copyrighted.  This software/database is freely available to the public for
use without a copyright notice.  Restrictions cannot be placed on its present
or future use. 

Although all reasonable efforts have been taken to ensure the accuracy and
reliability of the software and data, the National Human Genome Research
Institute (NHGRI) and the U.S. Government does not and cannot warrant the
performance or results that may be obtained by using this software or data.
NHGRI and the U.S.  Government disclaims all warranties as to performance,
merchantability or fitness for any particular purpose. 

In any work or product derived from this material, proper attribution of the
authors as the source of the software or data should be made, using "NHGRI
Cancer Genetics and Comparative Genomics Branch" as the citation. 

=cut
